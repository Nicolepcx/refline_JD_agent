{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKWGzsZ926uH",
        "outputId": "37429d10-277b-4820-8520-deacffcd3a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/210.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain\\\n",
        "                langgraph==1.0.5 \\\n",
        "                langchain-openai \\\n",
        "                langchain_experimental \\\n",
        "                aiosqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ss1kkvBE3SYa"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aXsVPGgsiG2",
        "outputId": "88e68c7b-5c12-49ee-8f77-f298375037a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.8/767.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "langchain-openai 1.1.6 requires openai<3.0.0,>=1.109.1, but you have openai 1.99.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q python-dotenv==1.0.1 \\\n",
        "                openpipe-art==0.5.0 \\\n",
        "                langgraph-checkpoint-sqlite==3.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L19RW6Z1wJbS",
        "outputId": "043de39d-5282-456f-a21c-5c1f92bd621d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "langchain==1.2.0\n",
            "langgraph==1.0.5\n",
            "langchain-openai==1.1.6\n",
            "langchain_experimental==0.4.1\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "packages = [\"langchain\", \"langgraph\", \"langchain-openai\", \"langchain_experimental\" ]\n",
        "\n",
        "for pkg in packages:\n",
        "    # Install the package\n",
        "    subprocess.run([\"pip\", \"install\", pkg])\n",
        "\n",
        "    # Get the version from pip show\n",
        "    result = subprocess.run(\n",
        "        [\"pip\", \"show\", pkg],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    version = None\n",
        "    for line in result.stdout.splitlines():\n",
        "        if line.startswith(\"Version:\"):\n",
        "            version = line.split(\":\", 1)[1].strip()\n",
        "            break\n",
        "\n",
        "    if version:\n",
        "        print(f\"{pkg}=={version}\")\n",
        "    else:\n",
        "        print(f\"Could not find version for {pkg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dZfRR_aZ4cjc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KTm92-ZfsUnN"
      },
      "outputs": [],
      "source": [
        "# Imports for API\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBC6syOkkwxO"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mAGPyHPaM0za"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WTmHkGrWM88M"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Literal, Annotated, TypedDict\n",
        "import json\n",
        "import uuid\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bl2ZgugPOIC8"
      },
      "outputs": [],
      "source": [
        "base_llm = ChatOpenAI(\n",
        "    model=\"Qwen/Qwen3-32B-fast\",\n",
        "    temperature=0,\n",
        "    api_key=NEBIUS_API_KEY,\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    extra_body={\n",
        "        \"top_k\": 20,\n",
        "        \"chat_template_kwargs\": {\"enable_thinking\": False},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SSJZZXWTOOFq"
      },
      "outputs": [],
      "source": [
        "#writer_model = base_llm.with_structured_output(JobBody).bind(\n",
        "#    temperature=cfg.temperature\n",
        "#)\n",
        "\n",
        "#style_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
        "#judge_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
        "\n",
        "judge_llm = ChatOpenAI(\n",
        "    model=\"Qwen/Qwen3-32B-fast\",\n",
        "    temperature=0,\n",
        "    api_key=NEBIUS_API_KEY,\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    extra_body={\n",
        "        \"top_k\": 20,\n",
        "        \"chat_template_kwargs\": {\"enable_thinking\": False},\n",
        "    },\n",
        ")\n",
        "\n",
        "style_llm = ChatOpenAI(\n",
        "    model=\"google/gemma-2-9b-it-fast\",\n",
        "    temperature=0,\n",
        "    api_key=NEBIUS_API_KEY,\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    extra_body={\n",
        "        \"top_k\": 20,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w8muMhFeOB7D"
      },
      "outputs": [],
      "source": [
        "class SkillItem(BaseModel):\n",
        "    name: str = Field(..., description=\"Example: Java, Django, Kubernetes\")\n",
        "    category: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Example: frontend, backend, cloud, database, devops, data\",\n",
        "    )\n",
        "    level: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Example: basic, intermediate, advanced, expert\",\n",
        "    )\n",
        "\n",
        "\n",
        "class JobBody(BaseModel):\n",
        "    job_description: str\n",
        "    requirements: List[str]\n",
        "    benefits: List[str]\n",
        "    duties: List[str]\n",
        "    summary: Optional[str]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqj9CAC4OD13"
      },
      "outputs": [],
      "source": [
        "class JobGenerationConfig(BaseModel):\n",
        "    language: Literal[\"en\", \"de\"] = \"en\"\n",
        "\n",
        "    formality: Literal[\"casual\", \"neutral\", \"formal\"] = \"neutral\"\n",
        "    company_type: Literal[\n",
        "        \"startup\",\n",
        "        \"scaleup\",\n",
        "        \"sme\",\n",
        "        \"corporate\",\n",
        "        \"public_sector\",\n",
        "        \"social_sector\",\n",
        "        \"agency\",\n",
        "        \"consulting\",\n",
        "        \"hospitality\",\n",
        "        \"retail\",\n",
        "    ] = \"scaleup\"\n",
        "\n",
        "    industry: Literal[\n",
        "        \"generic\",\n",
        "        \"finance\",\n",
        "        \"healthcare\",\n",
        "        \"social_care\",\n",
        "        \"public_it\",\n",
        "        \"ai_startup\",\n",
        "        \"ecommerce\",\n",
        "        \"manufacturing\",\n",
        "    ] = \"generic\"\n",
        "\n",
        "    seniority_label: Optional[Literal[\"intern\", \"junior\", \"mid\", \"senior\", \"lead\", \"principal\"]] = None\n",
        "    min_years_experience: Optional[int] = None\n",
        "    max_years_experience: Optional[int] = None\n",
        "\n",
        "    skills: List[SkillItem] = Field(default_factory=list)\n",
        "    benefit_keywords: List[str] = Field(default_factory=list)\n",
        "\n",
        "    @property\n",
        "    def temperature(self) -> float:\n",
        "        base = {\n",
        "            \"formal\": 0.2,\n",
        "            \"neutral\": 0.35,\n",
        "            \"casual\": 0.55,\n",
        "        }[self.formality]\n",
        "\n",
        "        if self.company_type in (\"startup\", \"hospitality\", \"retail\"):\n",
        "            base += 0.05\n",
        "        elif self.company_type in (\"public_sector\", \"social_sector\"):\n",
        "            base -= 0.05\n",
        "\n",
        "        if self.seniority_label in [\"senior\", \"lead\", \"principal\"]:\n",
        "            base -= 0.05\n",
        "        elif self.seniority_label in [\"intern\", \"junior\"]:\n",
        "            base += 0.05\n",
        "\n",
        "        if self.industry in [\"finance\", \"healthcare\", \"public_it\"]:\n",
        "            base -= 0.05\n",
        "        elif self.industry in [\"ai_startup\", \"ecommerce\"]:\n",
        "            base += 0.05\n",
        "\n",
        "        base = max(0.1, min(base, 0.75))\n",
        "        return base\n",
        "\n",
        "    def with_industry_defaults(self) -> \"JobGenerationConfig\":\n",
        "        cfg = self.model_copy(deep=True)\n",
        "\n",
        "        if cfg.industry == \"finance\":\n",
        "            if not cfg.benefit_keywords:\n",
        "                cfg.benefit_keywords = [\n",
        "                    \"berufliche Vorsorge (BVG)\",\n",
        "                    \"Weiterbildung im Bereich Finanzmarkt\",\n",
        "                    \"Bonusregelung\",\n",
        "                    \"hybrides Arbeiten\",\n",
        "                ]\n",
        "\n",
        "        if cfg.industry == \"healthcare\":\n",
        "            if not cfg.benefit_keywords:\n",
        "                cfg.benefit_keywords = [\n",
        "                    \"Work Life Balance\",\n",
        "                    \"betriebliche Gesundheitsförderung\",\n",
        "                    \"sicherer Arbeitsplatz im Gesundheitswesen\",\n",
        "                ]\n",
        "\n",
        "        if cfg.industry == \"public_it\":\n",
        "            cfg.company_type = \"public_sector\"\n",
        "            if not cfg.benefit_keywords:\n",
        "                cfg.benefit_keywords = [\n",
        "                    \"Vereinbarkeit von Beruf und Familie\",\n",
        "                    \"attraktive Sozialleistungen\",\n",
        "                    \"sicheres Arbeitsumfeld im öffentlichen Dienst (Bund/Kanton)\",\n",
        "                ]\n",
        "\n",
        "        if cfg.industry == \"ai_startup\":\n",
        "            cfg.company_type = \"startup\"\n",
        "            if not cfg.benefit_keywords:\n",
        "                cfg.benefit_keywords = [\n",
        "                    \"Remote Work in der Schweiz\",\n",
        "                    \"Mitarbeiterbeteiligung (Stock Options)\",\n",
        "                    \"Weiterbildungsbudget für Konferenzen\",\n",
        "                    \"modernes Büro im Stadtzentrum\",\n",
        "                ]\n",
        "\n",
        "        if cfg.industry == \"ecommerce\" and not cfg.benefit_keywords:\n",
        "            cfg.benefit_keywords = [\n",
        "                \"Mitarbeiterrabatte\",\n",
        "                \"flexible Arbeitszeiten\",\n",
        "                \"hybrides Arbeiten\",\n",
        "            ]\n",
        "\n",
        "        if cfg.industry == \"manufacturing\" and not cfg.benefit_keywords:\n",
        "            cfg.benefit_keywords = [\n",
        "                \"attraktive Schichtmodelle\",\n",
        "                \"Zuschuss zu Fahrtkosten\",\n",
        "                \"berufliche Vorsorge (BVG)\",\n",
        "            ]\n",
        "\n",
        "        return cfg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3nJ-lkwwqDA"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import re\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "# note -> import JobGenerationConfig, JobBody, JobState\n",
        "# note -> import import explain_temperature\n",
        "\n",
        "#base_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "\n",
        "# ── Schweizer Schriftdeutsch helpers (inline for notebook) ──\n",
        "\n",
        "def _replace_eszett(text: str) -> str:\n",
        "    \"\"\"Replace every ß with ss.  Swiss German never uses Eszett.\"\"\"\n",
        "    return text.replace(\"ß\", \"ss\")\n",
        "\n",
        "_CH_TERM_MAP = [\n",
        "    (r\"\\bTarifvertrag\\b\", \"Gesamtarbeitsvertrag (GAV)\"),\n",
        "    (r\"\\bGehalt\\b\", \"Salär\"),\n",
        "    (r\"\\bGehalts\\b\", \"Salärs\"),\n",
        "    (r\"\\bGehaltsvorstellung\\b\", \"Salärvorstellung\"),\n",
        "    (r\"\\bGehaltsabrechnung\\b\", \"Lohnabrechnung\"),\n",
        "    (r\"\\bArbeitnehmer\\b\", \"Arbeitnehmende\"),\n",
        "    (r\"\\bAbitur\\b\", \"Matura\"),\n",
        "    (r\"\\bUrlaub\\b\", \"Ferien\"),\n",
        "    (r\"\\bUrlaubstage\\b\", \"Ferientage\"),\n",
        "    (r\"\\bbetriebliche Altersvorsorge\\b\", \"berufliche Vorsorge (BVG)\"),\n",
        "    (r\"\\bBetriebsrente\\b\", \"Pensionskasse (BVG)\"),\n",
        "    (r\"\\bFahrrad\\b\", \"Velo\"),\n",
        "    (r\"\\bStraßenbahn\\b\", \"Tram\"),\n",
        "]\n",
        "\n",
        "def _enforce_swiss_german(text: str) -> str:\n",
        "    \"\"\"ß→ss + DE-DE→DE-CH vocabulary.\"\"\"\n",
        "    text = _replace_eszett(text)\n",
        "    for pattern, replacement in _CH_TERM_MAP:\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text\n",
        "\n",
        "def _enforce_swiss_german_on_list(items: List[str]) -> List[str]:\n",
        "    return [_enforce_swiss_german(item) for item in items]\n",
        "\n",
        "CH_SCHRIFTDEUTSCH_PROMPT_BLOCK = \"\"\"\\\n",
        "## Schweizer Schriftdeutsch (OBLIGATORISCH)\n",
        "\n",
        "Du schreibst AUSSCHLIESSLICH in Schweizer Schriftdeutsch (CH-Deutsch).\n",
        "Beachte folgende Regeln STRIKT:\n",
        "\n",
        "### Orthografie\n",
        "- NIEMALS «ß» verwenden. Immer «ss» schreiben (z.B. «gross» statt «groß», «Strasse» statt «Straße»).\n",
        "\n",
        "### Wortschatz (CH-spezifisch)\n",
        "- «Salär» statt «Gehalt»\n",
        "- «Gesamtarbeitsvertrag (GAV)» statt «Tarifvertrag»\n",
        "- «Ferien» statt «Urlaub»\n",
        "- «Matura» statt «Abitur»\n",
        "- «berufliche Vorsorge (BVG)» statt «betriebliche Altersvorsorge»\n",
        "- «Pensionskasse» statt «Betriebsrente»\n",
        "- «Arbeitnehmende» statt «Arbeitnehmer»\n",
        "\n",
        "### Stilistische Merkmale\n",
        "- Neutraler, sachlicher Ton (weniger werblich als DE-DE)\n",
        "- Etwas kürzere Sätze als in Deutschland üblich\n",
        "- Weniger rhetorischer Schmuck, weniger Ausrufezeichen\n",
        "- Prozedurale Klarheit hat Vorrang vor emotionaler Ansprache\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def render_job_body(\n",
        "    job_title: str,\n",
        "    cfg: JobGenerationConfig,\n",
        "    temperature: float | None = None,\n",
        ") -> JobBody:\n",
        "    \"\"\"\n",
        "    Pure JD generator.\n",
        "    Builds the prompt from JobGenerationConfig and returns a JobBody instance.\n",
        "    No LangGraph state, no messages list, no JSON.\n",
        "    German output always uses Schweizer Schriftdeutsch (no ß, CH vocabulary).\n",
        "    \"\"\"\n",
        "\n",
        "    cfg = cfg.with_industry_defaults()\n",
        "    lang = cfg.language\n",
        "    temp = temperature if temperature is not None else cfg.temperature\n",
        "\n",
        "    writer_model = base_llm.with_structured_output(JobBody).bind(\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    # tone line (German: includes explicit Sie/du pronoun rule)\n",
        "    if lang == \"en\":\n",
        "        tone_map = {\n",
        "            \"casual\": \"Use a friendly modern tone, but stay professional.\",\n",
        "            \"neutral\": \"Use a clear neutral professional tone.\",\n",
        "            \"formal\": \"Use a formal corporate tone.\",\n",
        "        }\n",
        "    else:\n",
        "        tone_map = {\n",
        "            \"casual\": (\n",
        "                \"Verwende einen freundlichen modernen, aber professionellen Ton. \"\n",
        "                \"WICHTIG: Verwende durchgehend die «du»-Anrede (duzen). \"\n",
        "                \"Beispiel: «Du arbeitest…», «Dein Team…», «Wir bieten dir…». \"\n",
        "                \"Verwende NIEMALS «Sie» oder «Ihnen» als Höflichkeitsform.\"\n",
        "            ),\n",
        "            \"neutral\": (\n",
        "                \"Verwende einen klaren sachlich professionellen Ton. \"\n",
        "                \"WICHTIG: Verwende durchgehend die «Sie»-Anrede (siezen). \"\n",
        "                \"Beispiel: «Sie arbeiten…», «Ihr Team…», «Wir bieten Ihnen…». \"\n",
        "                \"Verwende NIEMALS «du» oder «dir» als Anrede.\"\n",
        "            ),\n",
        "            \"formal\": (\n",
        "                \"Verwende einen formellen, eher konservativen Ton. \"\n",
        "                \"WICHTIG: Verwende durchgehend die «Sie»-Anrede (siezen). \"\n",
        "                \"Beispiel: «Sie arbeiten…», «Ihr Team…», «Wir bieten Ihnen…». \"\n",
        "                \"Verwende NIEMALS «du» oder «dir» als Anrede.\"\n",
        "            ),\n",
        "        }\n",
        "    tone_line = tone_map[cfg.formality]\n",
        "\n",
        "    # company type line\n",
        "    if lang == \"en\":\n",
        "        type_map = {\n",
        "            \"startup\": \"The company is a young startup with a fast paced environment.\",\n",
        "            \"scaleup\": \"The company is a growing scaleup with an established product.\",\n",
        "            \"sme\": \"The company is a small or medium-sized enterprise (SME) with close-knit teams and a pragmatic work culture.\",\n",
        "            \"corporate\": \"The company is a larger established company.\",\n",
        "            \"public_sector\": \"The organization operates in the public sector.\",\n",
        "            \"social_sector\": \"The organization is a non-profit or social sector entity with a purpose-driven mission.\",\n",
        "            \"agency\": \"The company is a digital agency working for multiple clients.\",\n",
        "            \"consulting\": \"The company is a consulting firm that delivers client projects.\",\n",
        "            \"hospitality\": \"The company operates in the hospitality sector (e.g. restaurant franchise, gastronomy) with a hands-on, team-oriented culture.\",\n",
        "            \"retail\": \"The company operates in retail with a customer-focused, dynamic work environment.\",\n",
        "        }\n",
        "    else:\n",
        "        type_map = {\n",
        "            \"startup\": \"Das Unternehmen ist ein junges Startup mit dynamischem Umfeld.\",\n",
        "            \"scaleup\": \"Das Unternehmen ist ein wachsendes Scaleup mit etabliertem Produkt.\",\n",
        "            \"sme\": \"Das Unternehmen ist ein KMU mit eingespielten Teams und einer pragmatischen Arbeitskultur.\",\n",
        "            \"corporate\": \"Das Unternehmen ist ein grösseres etabliertes Unternehmen.\",\n",
        "            \"public_sector\": \"Die Organisation ist im öffentlichen Sektor tätig.\",\n",
        "            \"social_sector\": \"Die Organisation ist eine gemeinnützige Einrichtung oder Stiftung mit einer sinnstiftenden Mission.\",\n",
        "            \"agency\": \"Das Unternehmen ist eine Agentur mit verschiedenen Kundenprojekten.\",\n",
        "            \"consulting\": \"Das Unternehmen ist ein Beratungsunternehmen mit vielfältigen Kundenprojekten.\",\n",
        "            \"hospitality\": \"Das Unternehmen ist in der Gastronomie tätig (z.B. Restaurantkette) mit einer praxisnahen, teamorientierten Kultur.\",\n",
        "            \"retail\": \"Das Unternehmen ist im Detailhandel tätig mit einem kundenorientierten, dynamischen Arbeitsumfeld.\",\n",
        "        }\n",
        "    company_line = type_map[cfg.company_type]\n",
        "\n",
        "    # seniority line\n",
        "    seniority_bits: List[str] = []\n",
        "    if cfg.seniority_label:\n",
        "        if lang == \"en\":\n",
        "            seniority_bits.append(f\"The role is a {cfg.seniority_label} level position.\")\n",
        "        else:\n",
        "            seniority_bits.append(f\"Die Rolle ist auf {cfg.seniority_label} Level ausgerichtet.\")\n",
        "    if cfg.min_years_experience is not None:\n",
        "        if lang == \"en\":\n",
        "            if cfg.max_years_experience:\n",
        "                seniority_bits.append(\n",
        "                    f\"Target experience range is {cfg.min_years_experience} to {cfg.max_years_experience} years.\"\n",
        "                )\n",
        "            else:\n",
        "                seniority_bits.append(\n",
        "                    f\"Target experience is at least {cfg.min_years_experience} years.\"\n",
        "                )\n",
        "        else:\n",
        "            if cfg.max_years_experience:\n",
        "                seniority_bits.append(\n",
        "                    f\"Die gewünschte Erfahrung liegt zwischen {cfg.min_years_experience} und {cfg.max_years_experience} Jahren.\"\n",
        "                )\n",
        "            else:\n",
        "                seniority_bits.append(\n",
        "                    f\"Gesucht werden Kandidatinnen und Kandidaten mit mindestens {cfg.min_years_experience} Jahren Berufserfahrung.\"\n",
        "                )\n",
        "    seniority_line = \" \".join(seniority_bits)\n",
        "\n",
        "    # skills line\n",
        "    skills_text = \", \".join([s.name for s in cfg.skills]) if cfg.skills else \"\"\n",
        "    if lang == \"en\":\n",
        "        skills_line = (\n",
        "            f\"Required core skills: {skills_text}.\"\n",
        "            if skills_text\n",
        "            else \"Infer reasonable skills for this job title and industry.\"\n",
        "        )\n",
        "    else:\n",
        "        skills_line = (\n",
        "            f\"Zentrale Skills: {skills_text}.\"\n",
        "            if skills_text\n",
        "            else \"Ergänze sinnvolle Skills passend zu Titel und Branche.\"\n",
        "        )\n",
        "\n",
        "    # benefits line\n",
        "    benefit_tags = \", \".join(cfg.benefit_keywords) if cfg.benefit_keywords else \"\"\n",
        "    if lang == \"en\":\n",
        "        benefits_line = (\n",
        "            \"Use these benefit keywords and turn them into nicely written bullet points: \"\n",
        "            f\"{benefit_tags}.\"\n",
        "            if benefit_tags\n",
        "            else \"Propose a realistic set of benefits for this industry and company type.\"\n",
        "        )\n",
        "    else:\n",
        "        benefits_line = (\n",
        "            \"Nutze diese Benefit Stichworte und formuliere daraus ansprechende Bullet Points: \"\n",
        "            f\"{benefit_tags}.\"\n",
        "            if benefit_tags\n",
        "            else \"Schlage ein realistisches Paket an Benefits für diese Branche und diesen Unternehmenstyp vor.\"\n",
        "        )\n",
        "\n",
        "    # CH prompt block for German generation\n",
        "    ch_block = \"\"\n",
        "    if lang == \"de\":\n",
        "        ch_block = CH_SCHRIFTDEUTSCH_PROMPT_BLOCK + \"\\n\"\n",
        "\n",
        "    # ── Sentence-start variety (AGENTS.md Rule 5) ──\n",
        "    variety_en = (\n",
        "        \"\\n## Sentence-Start Variety (MANDATORY)\\n\"\n",
        "        \"Every bullet-point list (duties, requirements, benefits) MUST vary how sentences begin.\\n\"\n",
        "        \"NEVER start more than 2 bullets the same way (e.g. 'You will…', 'Be responsible for…').\\n\"\n",
        "        \"Mix these openings across each list:\\n\"\n",
        "        \"- Lead with the topic area (e.g. 'Cloud infrastructure: design and maintain…')\\n\"\n",
        "        \"- Start with an action verb (e.g. 'Design scalable APIs…')\\n\"\n",
        "        \"- Open with context (e.g. 'In close collaboration with the data team, …')\\n\"\n",
        "        \"- Use a noun phrase (e.g. 'Ownership of the CI/CD pipeline…')\\n\"\n",
        "        \"- Vary the subject: you / we / the team / this role\\n\"\n",
        "    )\n",
        "    variety_de = (\n",
        "        \"\\n## Abwechslung bei Satzanfängen (OBLIGATORISCH)\\n\"\n",
        "        \"Jede Aufzählung (Aufgaben, Anforderungen, Benefits) MUSS unterschiedliche Satzanfänge verwenden.\\n\"\n",
        "        \"NIEMALS mehr als 2 Punkte gleich beginnen (z.B. immer «Sie …» oder «Du …»).\\n\"\n",
        "        \"Verwende mindestens 3 dieser Varianten pro Liste:\\n\"\n",
        "        \"- Mit dem Themenbereich beginnen (z.B. «Cloud-Infrastruktur: Entwurf und Wartung…»)\\n\"\n",
        "        \"- Mit einem Verb starten (z.B. «Entwirf skalierbare APIs…» oder «Skalierbare APIs entwerfen…»)\\n\"\n",
        "        \"- Kontextbezogener Einstieg (z.B. «In enger Zusammenarbeit mit dem Data-Team…»)\\n\"\n",
        "        \"- Substantivische Wendung (z.B. «Verantwortung für die CI/CD-Pipeline…»)\\n\"\n",
        "        \"- Subjekt wechseln: Sie/Du / Wir / Das Team / Diese Rolle\\n\"\n",
        "    )\n",
        "\n",
        "    # prompt\n",
        "    if lang == \"en\":\n",
        "        prompt = (\n",
        "            \"You are an experienced HR copywriter for a recruitment platform.\\n\"\n",
        "            f\"{tone_line}\\n\"\n",
        "            f\"{company_line}\\n\"\n",
        "            f\"{seniority_line}\\n\"\n",
        "            f\"{skills_line}\\n\"\n",
        "            f\"{benefits_line}\\n\"\n",
        "            f\"{variety_en}\\n\"\n",
        "            f\"Job title: {job_title}\\n\\n\"\n",
        "            \"Produce a JobBody instance in English.\\n\"\n",
        "            \"job_description: 2 to 4 sentences for role and context.\\n\"\n",
        "            \"requirements: 6 to 10 bullets matching seniority and skills.\\n\"\n",
        "            \"benefits: 4 to 8 bullets, phrasing the benefit keywords naturally.\\n\"\n",
        "            \"duties: 5 to 8 bullets describing day to day responsibilities.\\n\"\n",
        "            \"summary: 1 short closing line inviting candidates to apply.\\n\"\n",
        "        )\n",
        "    else:\n",
        "        prompt = (\n",
        "            \"Du bist eine erfahrene HR Texterin für eine Recruiting Plattform.\\n\"\n",
        "            f\"{ch_block}\"\n",
        "            f\"{tone_line}\\n\"\n",
        "            f\"{company_line}\\n\"\n",
        "            f\"{seniority_line}\\n\"\n",
        "            f\"{skills_line}\\n\"\n",
        "            f\"{benefits_line}\\n\"\n",
        "            f\"{variety_de}\\n\"\n",
        "            f\"Stellentitel: {job_title}\\n\\n\"\n",
        "            \"Erstelle eine JobBody Struktur auf Schweizer Schriftdeutsch.\\n\"\n",
        "            \"job_description: 2 bis 4 Sätze zu Rolle und Kontext.\\n\"\n",
        "            \"requirements: 6 bis 10 Stichpunkte, passend zur Seniorität und zu den Skills.\\n\"\n",
        "            \"benefits: 4 bis 8 Stichpunkte, formuliere die Benefit Stichworte aus.\\n\"\n",
        "            \"duties: 5 bis 8 Stichpunkte zu den täglichen Aufgaben.\\n\"\n",
        "            \"summary: 1 kurzer Abschlusssatz, der zur Bewerbung einlädt.\\n\"\n",
        "        )\n",
        "\n",
        "    payload: JobBody = writer_model.invoke(prompt)\n",
        "\n",
        "    # ── Schweizer Schriftdeutsch post-processing (ß→ss + CH vocabulary) ──\n",
        "    if lang == \"de\":\n",
        "        payload.job_description = _enforce_swiss_german(payload.job_description)\n",
        "        payload.requirements = _enforce_swiss_german_on_list(payload.requirements)\n",
        "        payload.benefits = _enforce_swiss_german_on_list(payload.benefits)\n",
        "        payload.duties = _enforce_swiss_german_on_list(payload.duties)\n",
        "        if payload.summary:\n",
        "            payload.summary = _enforce_swiss_german(payload.summary)\n",
        "\n",
        "    return payload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCpfMB9s-Pq0"
      },
      "outputs": [],
      "source": [
        "def explain_temperature(cfg: JobGenerationConfig) -> str:\n",
        "    parts = []\n",
        "\n",
        "    base_map = {\"formal\": 0.2, \"neutral\": 0.35, \"casual\": 0.55}\n",
        "    base = base_map[cfg.formality]\n",
        "    parts.append(f\"Base from formality='{cfg.formality}': {base:.2f}\")\n",
        "\n",
        "    # company type\n",
        "    if cfg.company_type in (\"startup\", \"hospitality\", \"retail\"):\n",
        "        base += 0.05\n",
        "        parts.append(f\"Company type '{cfg.company_type}' => +0.05\")\n",
        "    elif cfg.company_type in (\"public_sector\", \"social_sector\"):\n",
        "        base -= 0.05\n",
        "        parts.append(f\"Company type '{cfg.company_type}' => -0.05\")\n",
        "    else:\n",
        "        parts.append(f\"Company type '{cfg.company_type}' => +0.00\")\n",
        "\n",
        "    # seniority\n",
        "    if cfg.seniority_label in [\"senior\", \"lead\", \"principal\"]:\n",
        "        base -= 0.05\n",
        "        parts.append(f\"Seniority '{cfg.seniority_label}' => -0.05\")\n",
        "    elif cfg.seniority_label in [\"intern\", \"junior\"]:\n",
        "        base += 0.05\n",
        "        parts.append(f\"Seniority '{cfg.seniority_label}' => +0.05\")\n",
        "    else:\n",
        "        parts.append(\"Seniority not set => +0.00\")\n",
        "\n",
        "    # industry\n",
        "    if cfg.industry in [\"finance\", \"healthcare\", \"public_it\"]:\n",
        "        base -= 0.05\n",
        "        parts.append(f\"Industry '{cfg.industry}' => -0.05\")\n",
        "    elif cfg.industry in [\"ai_startup\", \"ecommerce\"]:\n",
        "        base += 0.05\n",
        "        parts.append(f\"Industry '{cfg.industry}' => +0.05\")\n",
        "    else:\n",
        "        parts.append(f\"Industry '{cfg.industry}' => +0.00\")\n",
        "\n",
        "    clamped = max(0.1, min(base, 0.75))\n",
        "    if clamped != base:\n",
        "        parts.append(f\"Clamped to [0.10, 0.75] => {clamped:.2f}\")\n",
        "    else:\n",
        "        parts.append(f\"Final temperature => {clamped:.2f}\")\n",
        "\n",
        "    return \"\\n\".join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CaCLRGwA8zuT"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, TypedDict, List, Optional, Dict, Any, Literal\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "def merge_blackboard(\n",
        "    left: Optional[List[JobBody]],\n",
        "    right: Optional[List[JobBody]],\n",
        ") -> List[JobBody]:\n",
        "    if right is None:\n",
        "        return left or []\n",
        "    return right\n",
        "\n",
        "class JobState(TypedDict, total=False):\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "    job_title: str\n",
        "    config: JobGenerationConfig\n",
        "    company_urls: List[str]\n",
        "    scraped_text: Optional[str]\n",
        "\n",
        "    candidates: Annotated[List[JobBody], merge_blackboard]\n",
        "\n",
        "    job_body_json: Optional[str]\n",
        "    style_profile_json: Optional[str]\n",
        "    consistency_report_json: Optional[str]\n",
        "\n",
        "    ruler_run: Dict[str, Any]\n",
        "    ruler_runs: List[Dict[str, Any]]\n",
        "    feedback_label: Literal[\"accepted\", \"rejected\", \"edited\", \"no_feedback\"]\n",
        "    user_feedback: Optional[str]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p38F3T5z_1pi"
      },
      "outputs": [],
      "source": [
        "def generate_job_body(state: JobState) -> JobState:\n",
        "    cfg = state[\"config\"].with_industry_defaults()\n",
        "\n",
        "    debug_info = explain_temperature(cfg)\n",
        "    print(\"\\n[JobGenerationConfig temperature breakdown]\")\n",
        "    print(debug_info)\n",
        "    print()\n",
        "\n",
        "    jb = render_job_body(\n",
        "        job_title=state[\"job_title\"],\n",
        "        cfg=cfg,\n",
        "        temperature=cfg.temperature,\n",
        "    )\n",
        "\n",
        "    state[\"job_body_json\"] = jb.model_dump_json(indent=2, ensure_ascii=False)\n",
        "    state[\"messages\"].append(AIMessage(content=state[\"job_body_json\"]))\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EimimtlJ_7-a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "import art\n",
        "from art.rewards import ruler_score_group\n",
        "from openai.types.chat.chat_completion import Choice\n",
        "from openai.types.chat import ChatCompletionMessage\n",
        "\n",
        "\n",
        "def generate_job_body_candidate(\n",
        "    job_title: str,\n",
        "    cfg: JobGenerationConfig,\n",
        "    temp_jitter: float = 0.0,\n",
        ") -> JobBody:\n",
        "    \"\"\"Use the same logic as the graph, with a slightly adjusted temperature.\"\"\"\n",
        "    base_temp = cfg.temperature\n",
        "    temp = max(0.1, min(base_temp + temp_jitter, 0.9))\n",
        "    return render_job_body(job_title, cfg, temperature=temp)\n",
        "\n",
        "\n",
        "def jd_candidate_to_trajectory(\n",
        "    job_title: str,\n",
        "    cfg: JobGenerationConfig,\n",
        "    job_body: JobBody,\n",
        ") -> art.Trajectory:\n",
        "    \"\"\"\n",
        "    Wrap a JobBody candidate as a trajectory for RULER.\n",
        "    Messages:\n",
        "      system: what the judge should care about\n",
        "      user: config and job body\n",
        "      assistant: the job body content that is being judged\n",
        "    \"\"\"\n",
        "\n",
        "    system_msg = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are an expert HR quality judge. You evaluate job descriptions for clarity, \"\n",
        "            \"tone, alignment with the requested role, and usefulness to candidates. \"\n",
        "            \"You prefer job ads that are specific, concise, aligned with the seniority level, \"\n",
        "            \"and realistic for the company type and industry.\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    user_msg = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Evaluate the quality of the following job description.\\n\\n\"\n",
        "            f\"Job title: {job_title}\\n\\n\"\n",
        "            f\"Config JSON:\\n{cfg.model_dump_json(indent=2, ensure_ascii=False)}\\n\\n\"\n",
        "            f\"JobBody JSON:\\n{job_body.model_dump_json(indent=2, ensure_ascii=False)}\\n\"\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    assistant_msg = ChatCompletionMessage(\n",
        "        role=\"assistant\",\n",
        "        content=job_body.model_dump_json(indent=2, ensure_ascii=False),\n",
        "    )\n",
        "\n",
        "    choice = Choice(\n",
        "        finish_reason=\"stop\",\n",
        "        index=0,\n",
        "        message=assistant_msg,\n",
        "    )\n",
        "\n",
        "    traj = art.Trajectory(\n",
        "        messages_and_choices=[system_msg, user_msg, choice],\n",
        "        reward=0.0,\n",
        "    )\n",
        "    return traj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vXbZ3bsX__yI"
      },
      "outputs": [],
      "source": [
        "async def generate_best_job_body_with_ruler(\n",
        "    job_title: str,\n",
        "    cfg: JobGenerationConfig,\n",
        "    num_candidates: int = 3,\n",
        "    jitter: float = 0.1,\n",
        "    judge_model: str = \"openai/o3-mini\",\n",
        ") -> Tuple[JobBody, List[Tuple[float, JobBody]]]:\n",
        "    \"\"\"\n",
        "    Generate multiple JobBody candidates and use ART RULER to pick the best one.\n",
        "\n",
        "    Returns:\n",
        "      best_job_body,\n",
        "      list of (score, job_body) sorted by score descending.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1sample candidates with small temperature jitter\n",
        "    candidates: List[JobBody] = []\n",
        "    if num_candidates <= 0:\n",
        "        raise ValueError(\"num_candidates must be at least 1\")\n",
        "\n",
        "    offsets: List[float] = []\n",
        "    center = num_candidates // 2\n",
        "    for i in range(num_candidates):\n",
        "        offsets.append((i - center) * jitter)\n",
        "\n",
        "    for offset in offsets:\n",
        "        jb = generate_job_body_candidate(job_title, cfg, temp_jitter=offset)\n",
        "        candidates.append(jb)\n",
        "\n",
        "    # wrap as trajectories\n",
        "    trajectories = [\n",
        "        jd_candidate_to_trajectory(job_title, cfg, jb)\n",
        "        for jb in candidates\n",
        "    ]\n",
        "    group = art.TrajectoryGroup(trajectories)\n",
        "\n",
        "    # score with RULER\n",
        "    judged_group = await ruler_score_group(group, judge_model, debug=False)\n",
        "    if not judged_group:\n",
        "        # graceful fallback\n",
        "        return candidates[0], [(0.0, jb) for jb in candidates]\n",
        "\n",
        "    # 4. collect scores and sort\n",
        "    scored: List[Tuple[float, JobBody]] = []\n",
        "    for traj, jb in zip(judged_group.trajectories, candidates):\n",
        "        scored.append((traj.reward, jb))\n",
        "\n",
        "    scored_sorted = sorted(scored, key=lambda t: t[0], reverse=True)\n",
        "    best_score, best_job_body = scored_sorted[0]\n",
        "\n",
        "    print(\"\\n[JD RULER ranking]\")\n",
        "    for rank, (score, jb) in enumerate(scored_sorted, start=1):\n",
        "        print(f\"Rank {rank} | score={score:.3f}\")\n",
        "        print(\"  job_description:\", (jb.job_description or \"\")[:140], \"...\")\n",
        "    print()\n",
        "\n",
        "    return best_job_body, scored_sorted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dc71Dl4NpE7V"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import sqlite3\n",
        "import uuid\n",
        "from datetime import datetime, timezone\n",
        "from typing import Annotated, Any, Dict, List, Optional, TypedDict, Literal\n",
        "\n",
        "from langchain_core.messages import AIMessage, BaseMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "\n",
        "\n",
        "# Your imports\n",
        "# from your_project.models import JobGenerationConfig, JobBody, SkillItem\n",
        "# from your_project.jd_generator import render_job_body\n",
        "# from your_project.ruler import generate_best_job_body_with_ruler\n",
        "# from your_project.style import build_style_profile, build_consistency_report\n",
        "# from your_project.scrape import scrape_company_urls\n",
        "\n",
        "\n",
        "def merge_blackboard(\n",
        "    left: Optional[List[JobBody]],\n",
        "    right: Optional[List[JobBody]],\n",
        ") -> List[JobBody]:\n",
        "    if right is None:\n",
        "        return left or []\n",
        "    return right\n",
        "\n",
        "\n",
        "class JobState(TypedDict, total=False):\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "    job_title: str\n",
        "    config: \"JobGenerationConfig\"\n",
        "    company_urls: List[str]\n",
        "    scraped_text: Optional[str]\n",
        "\n",
        "    # IMPORTANT: keep this in the state schema\n",
        "    candidates: Annotated[List[JobBody], merge_blackboard]\n",
        "\n",
        "    job_body_json: Optional[str]\n",
        "    style_profile_json: Optional[str]\n",
        "    consistency_report_json: Optional[str]\n",
        "\n",
        "    ruler_run: Dict[str, Any]\n",
        "    ruler_runs: List[Dict[str, Any]]\n",
        "    feedback_label: Literal[\"accepted\", \"rejected\", \"edited\", \"no_feedback\"]\n",
        "    user_feedback: Optional[str]\n",
        "\n",
        "\n",
        "def _sha16(text: str) -> str:\n",
        "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:16]\n",
        "\n",
        "\n",
        "def _utc_now() -> str:\n",
        "    return datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "\n",
        "def _bucket(cfg: \"JobGenerationConfig\") -> str:\n",
        "    return \"|\".join(\n",
        "        [\n",
        "            cfg.language,\n",
        "            cfg.industry,\n",
        "            cfg.formality,\n",
        "            cfg.company_type,\n",
        "            cfg.seniority_label or \"none\",\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def _ruler_namespace(config: RunnableConfig) -> tuple[str, str]:\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    return (user_id, \"jd_ruler\")\n",
        "\n",
        "\n",
        "async def node_scrape_company(state: JobState) -> JobState:\n",
        "    \"\"\"\n",
        "    Optional stub. Keep it if you already scrape.\n",
        "    This should populate scraped_text and possibly company_urls.\n",
        "    \"\"\"\n",
        "    # scraped = await scrape_company_urls(state[\"company_urls\"])\n",
        "    # state[\"scraped_text\"] = scraped.text\n",
        "    return {\"scraped_text\": \"Company info text...\"}\n",
        "\n",
        "\n",
        "def node_build_style_profile(state: JobState) -> JobState:\n",
        "    \"\"\"\n",
        "    Optional stub. Keep it if you already produce style_profile_json.\n",
        "    \"\"\"\n",
        "    # style = build_style_profile(state)\n",
        "    # state[\"style_profile_json\"] = style.model_dump_json(indent=2, ensure_ascii=False)\n",
        "    return state\n",
        "\n",
        "async def node_generator_expert(state: JobState, config: RunnableConfig, *, store: BaseStore) -> Dict:\n",
        "    \"\"\"Expert: Initial Drafter. Pulls 'Gold Standards' from SQLite Store.\"\"\"\n",
        "    user_id = config[\"configurable\"].get(\"user_id\", \"default\")\n",
        "    cfg = state[\"config\"].with_industry_defaults()\n",
        "\n",
        "    # Access Shared Memory\n",
        "    past_gold = store.search((user_id, \"gold_standard\"), query=state[\"job_title\"], limit=2)\n",
        "\n",
        "    seeds = []\n",
        "    for i in range(3):\n",
        "        jb = generate_job_body_candidate(state[\"job_title\"], cfg, temp_jitter=(i * 0.1))\n",
        "        seeds.append(jb)\n",
        "\n",
        "    return {\"candidates\": seeds}\n",
        "\n",
        "async def node_style_expert(state: JobState, config: RunnableConfig, *, store: BaseStore) -> Dict:\n",
        "    \"\"\"Expert: Refiner. Pulls 'User Gripes' from SQLite Store to polish the blackboard.\"\"\"\n",
        "    user_id = config[\"configurable\"].get(\"user_id\", \"default\")\n",
        "    candidates = state.get(\"candidates\", [])\n",
        "\n",
        "    # Access Shared Memory\n",
        "    gripes = store.search((user_id, \"user_gripes\"), limit=3)\n",
        "    avoid_list = \"\\n\".join([f\"- {g.value['feedback']}\" for g in gripes])\n",
        "\n",
        "    # Creative Refinement: Usually you would call style_llm here\n",
        "    # We ensure we return the candidates so they stay on the blackboard\n",
        "    return {\"candidates\": candidates, \"is_refined\": True}\n",
        "\n",
        "async def node_ruler_curator(state: JobState) -> Dict:\n",
        "    \"\"\"Expert: Final Judge. Selects the winner from the blackboard.\"\"\"\n",
        "    candidates = state.get(\"candidates\", [])\n",
        "    if not candidates:\n",
        "        return {\"job_body_json\": \"Error: Blackboard was empty at Curate step.\"}\n",
        "\n",
        "    # RULER ranking logic\n",
        "    trajectories = [jd_candidate_to_trajectory(state[\"job_title\"], state[\"config\"], jb) for jb in candidates]\n",
        "    group = art.TrajectoryGroup(trajectories)\n",
        "    judged_group = await art.rewards.ruler_score_group(group, \"openai/o3-mini\")\n",
        "\n",
        "    if not judged_group:\n",
        "        # Graceful fallback: use first candidate\n",
        "        best_jb = candidates[0]\n",
        "        return {\n",
        "            \"job_body_json\": best_jb.model_dump_json(indent=2, ensure_ascii=False),\n",
        "            \"ruler_run\": {\"best_score\": 0.0, \"fallback\": True}\n",
        "        }\n",
        "\n",
        "    scored = sorted(zip(judged_group.trajectories, candidates), key=lambda x: x[0].reward, reverse=True)\n",
        "    best_jb = scored[0][1]\n",
        "\n",
        "    return {\n",
        "        \"job_body_json\": best_jb.model_dump_json(indent=2, ensure_ascii=False),\n",
        "        \"ruler_run\": {\"best_score\": float(scored[0][0].reward)}\n",
        "    }\n",
        "\n",
        "def node_build_consistency_report(state: JobState) -> JobState:\n",
        "    \"\"\"\n",
        "    Optional stub. If you already have a consistency report, keep it.\n",
        "    This should evaluate job_body_json against style_profile_json and scraped_text.\n",
        "    \"\"\"\n",
        "    # report = build_consistency_report(state)\n",
        "    # state[\"consistency_report_json\"] = report.model_dump_json(indent=2, ensure_ascii=False)\n",
        "    return state\n",
        "\n",
        "\n",
        "import aiosqlite\n",
        "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "\n",
        "def node_persist_feedback_to_store(state: JobState, config: RunnableConfig, *, store: BaseStore) -> Dict:\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    final_body = state.get(\"job_body_json\")\n",
        "\n",
        "    if state.get(\"feedback_label\") == \"accepted\" and final_body:\n",
        "        # Save to SQLite for future 'generator' runs\n",
        "        store.put((user_id, \"gold_standard\"), state[\"job_title\"], {\"body\": final_body})\n",
        "\n",
        "    return {} # Side-effect node\n",
        "\n",
        "async def build_graph(*, sqlite_path: str = \"jd_threads.sqlite\"):\n",
        "    workflow = StateGraph(JobState)\n",
        "\n",
        "    workflow.add_node(\"scrape_company\", node_scrape_company)\n",
        "    workflow.add_node(\"generator\", node_generator_expert)\n",
        "    workflow.add_node(\"style_expert\", node_style_expert)\n",
        "    workflow.add_node(\"curator\", node_ruler_curator)\n",
        "    workflow.add_node(\"persist\", node_persist_feedback_to_store)\n",
        "\n",
        "    workflow.add_edge(START, \"scrape_company\")\n",
        "    workflow.add_edge(\"scrape_company\", \"generator\")\n",
        "    workflow.add_edge(\"generator\", \"style_expert\")\n",
        "    workflow.add_edge(\"style_expert\", \"curator\")\n",
        "    workflow.add_edge(\"curator\", \"persist\")\n",
        "    workflow.add_edge(\"persist\", END)\n",
        "\n",
        "    conn = await aiosqlite.connect(sqlite_path)\n",
        "    if not hasattr(conn, \"is_alive\"): conn.is_alive = lambda: True\n",
        "\n",
        "    checkpointer = AsyncSqliteSaver(conn)\n",
        "    store = InMemoryStore() # Use a persistent Store for production\n",
        "\n",
        "    return workflow.compile(checkpointer=checkpointer, store=store), conn, store\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nPI084iPFlWf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import uuid\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Optional, List\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "\n",
        "def _utc_now_compact() -> str:\n",
        "    return datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "\n",
        "\n",
        "def _ensure_dir(p: Path) -> None:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def _json_dump(path: Path, obj: Any) -> None:\n",
        "    _ensure_dir(path.parent)\n",
        "    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def _jsonl_append(path: Path, obj: Any) -> None:\n",
        "    _ensure_dir(path.parent)\n",
        "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "def _safe_excerpt(s: Optional[str], n: int) -> Optional[str]:\n",
        "    if not s:\n",
        "        return None\n",
        "    return s[:n] + (\"...\" if len(s) > n else \"\")\n",
        "\n",
        "\n",
        "def _artifact_delta(payload: Any) -> Dict[str, Any]:\n",
        "    \"\"\"Defensive tracker for Blackboard changes during streaming.\"\"\"\n",
        "    # Ensure payload is a dictionary before calling .get()\n",
        "    if not isinstance(payload, dict):\n",
        "        return {\"info\": \"Node returned non-dict payload\"}\n",
        "\n",
        "    candidates = payload.get(\"candidates\", [])\n",
        "\n",
        "    # Safely get the description of the first candidate if it exists\n",
        "    first_desc = None\n",
        "    if candidates and len(candidates) > 0:\n",
        "        # Check if it's a JobBody object or a dict\n",
        "        first_obj = candidates[0]\n",
        "        first_desc = getattr(first_obj, \"job_description\", None)\n",
        "\n",
        "    return {\n",
        "        \"candidate_count\": len(candidates),\n",
        "        \"first_candidate_excerpt\": _safe_excerpt(first_desc, 200),\n",
        "        \"job_body_json_excerpt\": _safe_excerpt(payload.get(\"job_body_json\"), 800),\n",
        "        \"ruler_run\": payload.get(\"ruler_run\"),\n",
        "        \"is_refined\": payload.get(\"is_refined\"),\n",
        "    }\n",
        "\n",
        "\n",
        "from typing import Any, Dict, List, Optional\n",
        "from pydantic import BaseModel\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "def _message_to_jsonable(m: BaseMessage) -> Dict[str, Any]:\n",
        "    d: Dict[str, Any] = {\n",
        "        \"type\": m.__class__.__name__,\n",
        "        \"content\": getattr(m, \"content\", None),\n",
        "    }\n",
        "\n",
        "    # Some message types have role / name\n",
        "    role = getattr(m, \"role\", None)\n",
        "    if role is not None:\n",
        "        d[\"role\"] = role\n",
        "\n",
        "    name = getattr(m, \"name\", None)\n",
        "    if name is not None:\n",
        "        d[\"name\"] = name\n",
        "\n",
        "    # Tool calls show up on AIMessage in many setups\n",
        "    tool_calls = getattr(m, \"tool_calls\", None)\n",
        "    if tool_calls:\n",
        "        d[\"tool_calls\"] = tool_calls\n",
        "\n",
        "    additional_kwargs = getattr(m, \"additional_kwargs\", None)\n",
        "    if additional_kwargs:\n",
        "        d[\"additional_kwargs\"] = additional_kwargs\n",
        "\n",
        "    response_metadata = getattr(m, \"response_metadata\", None)\n",
        "    if response_metadata:\n",
        "        d[\"response_metadata\"] = response_metadata\n",
        "\n",
        "    return d\n",
        "\n",
        "\n",
        "def _to_jsonable(obj: Any) -> Any:\n",
        "    if isinstance(obj, BaseMessage):\n",
        "        return _message_to_jsonable(obj)\n",
        "    if isinstance(obj, BaseModel):\n",
        "        return obj.model_dump()\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: _to_jsonable(v) for k, v in obj.items()}\n",
        "    if isinstance(obj, (list, tuple)):\n",
        "        return [_to_jsonable(v) for v in obj]\n",
        "    return obj\n",
        "\n",
        "\n",
        "def _state_to_jsonable(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    s = dict(state)\n",
        "    if \"config\" in s:\n",
        "        s[\"config\"] = _to_jsonable(s[\"config\"])\n",
        "    if \"messages\" in s and isinstance(s[\"messages\"], list):\n",
        "        s[\"messages\"] = [_message_to_jsonable(m) for m in s[\"messages\"]]\n",
        "    return _to_jsonable(s)\n",
        "\n",
        "\n",
        "\n",
        "async def run_example():\n",
        "    graph, conn, store = await build_graph(sqlite_path=\"jd_threads.sqlite\")\n",
        "\n",
        "    run_id = f\"{_utc_now_compact()}_{uuid.uuid4().hex[:8]}\"\n",
        "    run_dir = Path(\"artifacts\") / run_id\n",
        "    events_path = run_dir / \"events.jsonl\"\n",
        "\n",
        "    try:\n",
        "        initial_state: JobState = {\n",
        "            \"messages\": [],\n",
        "            \"job_title\": \"Senior AI Agent Engineer\",\n",
        "            \"candidates\": [],\n",
        "            \"config\": JobGenerationConfig(\n",
        "                language=\"en\",\n",
        "                industry=\"ai_startup\",\n",
        "                formality=\"casual\",\n",
        "                company_type=\"scaleup\",\n",
        "                seniority_label=\"senior\",\n",
        "                min_years_experience=5,\n",
        "                skills=[\n",
        "                    SkillItem(name=\"Python\", category=\"backend\", level=\"advanced\"),\n",
        "                    SkillItem(name=\"LLM orchestration (LangGraph, LangChain)\", category=\"backend\"),\n",
        "                ],\n",
        "                benefit_keywords=[\"hybrid work in Switzerland\", \"continuing education in AI and ML\"],\n",
        "            ),\n",
        "            \"company_urls\": [\n",
        "                \"https://www.refline.io/en/index.html\",\n",
        "                \"https://www.refline.io/en/aboutus.html\",\n",
        "                \"https://www.refline.io/en/career.html\",\n",
        "            ],\n",
        "            \"job_body_json\": None,\n",
        "            \"style_profile_json\": None,\n",
        "            \"consistency_report_json\": None,\n",
        "            \"scraped_text\": None,\n",
        "            \"feedback_label\": \"no_feedback\",\n",
        "            \"user_feedback\": None,\n",
        "        }\n",
        "\n",
        "        config: RunnableConfig = {\n",
        "            \"configurable\": {\"thread_id\": \"thread_001\", \"user_id\": \"user_123\"}\n",
        "        }\n",
        "\n",
        "        # persist inputs for reproducibility\n",
        "        _json_dump(\n",
        "            run_dir / \"input.json\",\n",
        "            {\n",
        "                \"run_id\": run_id,\n",
        "                \"thread_id\": config[\"configurable\"][\"thread_id\"],\n",
        "                \"user_id\": config[\"configurable\"][\"user_id\"],\n",
        "                \"initial_state\": _state_to_jsonable(initial_state),\n",
        "            },\n",
        "        )\n",
        "\n",
        "        # stream updates and also produce a final result\n",
        "        async for update in graph.astream(initial_state, config=config, stream_mode=\"updates\"):\n",
        "            for node, payload in update.items():\n",
        "                record = {\n",
        "                    \"ts\": datetime.now(timezone.utc).isoformat(),\n",
        "                    \"node\": node,\n",
        "                    \"delta\": _artifact_delta(payload),\n",
        "                }\n",
        "                _jsonl_append(events_path, record)\n",
        "\n",
        "                print(f\"\\n[Expert Active: {node}]\")\n",
        "                d = record[\"delta\"]\n",
        "\n",
        "                if d.get(\"candidate_count\"):\n",
        "                    print(f\"  Blackboard Update: {d['candidate_count']} candidates present.\")\n",
        "                    print(f\"  Sample Draft: {d['first_candidate_excerpt']}\")\n",
        "\n",
        "                if d.get(\"is_refined\"):\n",
        "                    print(\"  ✨ Style Expert finished polishing candidates based on user history.\")\n",
        "\n",
        "                if d.get(\"job_body_json_excerpt\"):\n",
        "                    print(f\"  Curator selected final candidate (Size: {len(payload['job_body_json'])} chars)\")\n",
        "\n",
        "                if d.get(\"ruler_run\"):\n",
        "                    rr = d[\"ruler_run\"]\n",
        "                    print(f\"  RULER Ranking: Best Score = {rr.get('best_score')}\")\n",
        "\n",
        "        # IMPORTANT: async state accessors with AsyncSqliteSaver\n",
        "        latest = await graph.aget_state(config)\n",
        "        history = [snap async for snap in graph.aget_state_history(config)]\n",
        "\n",
        "        final_values = latest.values\n",
        "        _json_dump(run_dir / \"final_state_values.json\", _state_to_jsonable(final_values))\n",
        "\n",
        "\n",
        "        # optional: write big blobs separately for convenience\n",
        "        # Ensure we save the candidates as well for debugging the creative flow\n",
        "        if final_values.get(\"candidates\"):\n",
        "            candidates_json = json.dumps([c.model_dump() for c in final_values[\"candidates\"]], indent=2)\n",
        "            (run_dir / \"blackboard_final_candidates.json\").write_text(candidates_json, encoding=\"utf-8\")\n",
        "\n",
        "        if final_values.get(\"job_body_json\"):\n",
        "            (run_dir / \"final_selection.json\").write_text(final_values[\"job_body_json\"], encoding=\"utf-8\")\n",
        "\n",
        "        # Log specific User Context found in Shared Memory for this run\n",
        "        if final_values.get(\"ruler_run\"):\n",
        "            _json_dump(run_dir / \"ruler_performance.json\", final_values[\"ruler_run\"])\n",
        "\n",
        "        print(\"\\n===== FINAL JOB BODY =====\\n\", final_values.get(\"job_body_json\") or \"\")\n",
        "        print(\"\\n===== FINAL CONSISTENCY REPORT =====\\n\", final_values.get(\"consistency_report_json\") or \"\")\n",
        "        print(f\"\\n[artifacts] wrote: {run_dir}\")\n",
        "        print(f\"[artifacts] events: {events_path}\")\n",
        "\n",
        "        # keep return signature as you had it\n",
        "        return final_values, latest, history\n",
        "\n",
        "    finally:\n",
        "        await conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnOiwhJ-R84N",
        "outputId": "53792f4d-2bf3-43fb-a024-40ddd4691672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Expert Active: scrape_company]\n",
            "\n",
            "[Expert Active: generator]\n",
            "  Blackboard Update: 3 candidates present.\n",
            "  Sample Draft: As a Senior AI Agent Engineer, you'll be at the forefront of building and deploying intelligent systems that drive our startup's mission forward. You'll work in a fast-paced, collaborative environment...\n",
            "\n",
            "[Expert Active: style_expert]\n",
            "  Blackboard Update: 3 candidates present.\n",
            "  Sample Draft: As a Senior AI Agent Engineer, you'll be at the forefront of building and deploying intelligent systems that drive our startup's mission forward. You'll work in a fast-paced, collaborative environment...\n",
            "\n",
            "[Expert Active: curator]\n",
            "  Curator selected final candidate (Size: 2059 chars)\n",
            "  RULER Ranking: Best Score = 0.93\n",
            "\n",
            "[Expert Active: persist]\n",
            "\n",
            "===== FINAL JOB BODY =====\n",
            " {\n",
            "  \"job_description\": \"Join a dynamic AI-driven startup in Switzerland and lead the development of cutting-edge AI agents. As a Senior AI Agent Engineer, you'll design, build, and orchestrate intelligent systems that solve real-world problems in a fast-paced, innovation-focused environment.\",\n",
            "  \"requirements\": [\n",
            "    \"5+ years of experience in software engineering with a strong focus on AI and machine learning\",\n",
            "    \"Expertise in Python, including building and deploying scalable AI applications\",\n",
            "    \"Proficiency in LLM orchestration frameworks such as LangGraph and LangChain\",\n",
            "    \"Hands-on experience designing and implementing AI agent architectures\",\n",
            "    \"Excellent problem-solving and analytical skills, with a track record of shipping high-impact solutions\",\n",
            "    \"Strong collaboration skills and the ability to mentor junior team members\",\n",
            "    \"Familiarity with MLOps practices and cloud platforms (AWS, GCP, Azure) is a plus\"\n",
            "  ],\n",
            "  \"benefits\": [\n",
            "    \"Hybrid work model with the flexibility to work from anywhere in Switzerland\",\n",
            "    \"Generous budget for continuing education in AI and machine learning\",\n",
            "    \"Access to the latest tools and technologies to stay at the forefront of AI innovation\",\n",
            "    \"A collaborative, fast-paced startup culture with real impact on the product and direction\"\n",
            "  ],\n",
            "  \"duties\": [\n",
            "    \"Design and implement AI agent systems using LLMs and orchestration frameworks\",\n",
            "    \"Collaborate with cross-functional teams to define and prioritize AI-driven features\",\n",
            "    \"Integrate and optimize AI models into production environments for scalability and performance\",\n",
            "    \"Conduct code reviews, mentor junior engineers, and contribute to team knowledge sharing\",\n",
            "    \"Stay up-to-date with AI research and bring new ideas to the development pipeline\",\n",
            "    \"Monitor and improve system performance through logging, metrics, and continuous feedback loops\"\n",
            "  ],\n",
            "  \"summary\": \"If you're passionate about building intelligent systems and want to shape the future of AI in a bold startup environment, we'd love to hear from you.\"\n",
            "}\n",
            "\n",
            "===== FINAL CONSISTENCY REPORT =====\n",
            " \n",
            "\n",
            "[artifacts] wrote: artifacts/20260107T141224Z_2cbca672\n",
            "[artifacts] events: artifacts/20260107T141224Z_2cbca672/events.jsonl\n"
          ]
        }
      ],
      "source": [
        "result, latest, history = await run_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BqXrX4MQUJ8y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
